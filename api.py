# -*- coding: utf-8 -*-
"""
@File       : api_server_async.py
@Description: æ™ºèƒ½åç‰‡ç¿»æ–° (æé€Ÿ URL æœ€ç»ˆç‰ˆ)
@Logic      : 
    1. å‚è€ƒå›¾: å›ºå®š URL (é›¶å¸¦å®½æ¶ˆè€—ï¼Œç§’å‘)
    2. ä¸»å›¾: çŸ«æ­£åç«‹å³ä¸Šä¼ æ¢ URL (æ··åˆåŠ é€Ÿï¼Œçœ50%å¸¦å®½)
    3. ç”»è´¨: 95 (æ— æŸé«˜æ¸…)
    4. è£åˆ‡: æ™ºèƒ½åŒé‡ä¿éšœ (çº¢æ¡†ä¼˜å…ˆ -> ResNetå…œåº•)
    5. å¹¶å‘: æš´åŠ›å…¨å¼€
@Usage      : nohup python -u api_server_async.py > runtime.log 2>&1 &
"""

import os
import io
import sys
import json
import time
import base64
import asyncio
import logging
import httpx
import cv2
import numpy as np
from typing import List, Optional
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from PIL import Image
from volcenginesdkarkruntime import Ark 
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# å¼•å…¥ä¼˜åŒ–åçš„ ResNet æ¨¡å—
from image_correct_optimized import processor

# ================= 1. æ—¥å¿—é…ç½® =================
logger = logging.getLogger("SmartCard")
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    formatter = logging.Formatter("%(asctime)s %(message)s", datefmt="%H:%M:%S")
    handler.setFormatter(formatter)
    logger.addHandler(handler)
logger.propagate = False

# ================= 2. å…¨å±€é…ç½® =================
class CONFIG:
    VOLC_API_KEY = ""
    VOLC_BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
    MODEL_GEN = "doubao-seedream-4-5-251128"
    MODEL_VISION = "doubao-seed-1-6-vision-250815"
    
    FIXED_GEN_SIZE = "3000x1824"

    # === æš´åŠ›å¹¶å‘é…ç½® ===
    # ç”±äºä½¿ç”¨äº† URL æ¨¡å¼ï¼Œå¸¦å®½å‹åŠ›æå°ï¼Œå¯ä»¥æ”¾å¿ƒæ‹‰æ»¡
    GPU_SEMAPHORE_LIMIT = 8
    API_SEMAPHORE_LIMIT = 50
    UPLOAD_SEMAPHORE_LIMIT = 50
    WORKFLOW_SEMAPHORE_LIMIT = 15


    # === ä¸Šä¼ æ¥å£ ===
    UPLOAD_API_URL = "https://tt.36588.com.cn/mcard/common/commonUpload"
    IMG_URL_PREFIX = "https://tt.36588.com.cn/mcard/assets/resource/imgs/normal/"

    REF_LOCAL_DIR = "/home/ubuntu/zj/restore/ref_imgs"
    
    # === [å·²å¡«å…¥] å‚è€ƒå›¾ URL é…ç½® (é›¶å¸¦å®½æ¶ˆè€—) ===
    REF_IMGS_URLS = [
        "https://tt.36588.com.cn/mcard/assets/resource/imgs/normal/printdiy1/M00/B9/17/oYYBAGll6wKAJWQTABAy8xidGMs775.png",
        "https://tt.36588.com.cn/mcard/assets/resource/imgs/normal/printdiy1/M00/B9/18/oYYBAGll6wqAKfDIABUkz0aLF5o094.png",
        "https://tt.36588.com.cn/mcard/assets/resource/imgs/normal/printdiy1/M00/B9/18/oYYBAGll6xCAMoBzAA8pW2TABec002.png",
        "https://tt.36588.com.cn/mcard/assets/resource/imgs/normal/printdiy1/M00/B9/19/oYYBAGll6xWAaDzhAA4BUvSCQIM375.png",
    ]

    # === Prompts ===
    PROMPT_DESCRIBE = """
    å¹³é¢è®¾è®¡è¿˜åŸä¸“å®¶ï¼šé€è¿‡å›¾åƒåˆ†æåŸå§‹æ•°å­—å¸ƒå±€ï¼ŒæŒ‰ã€èƒŒæ™¯ / å¡«å…… / è‰²å— / æ’ç‰ˆ / å›¾æ ‡ / å¹²æ‰° / é£æ ¼ã€‘7 éƒ¨åˆ†è¾“å‡ºã€‚
    æ³¨æ„ï¼šè¿™æ˜¯å¯¹ä¸€å¼ å·²ç»è¿‡çŸ«æ­£çš„å¹³é¢å›¾è¿›è¡Œåˆ†æã€‚
    ç²¾å‡†å¯¹é½åŸå›¾å¸ƒå±€ï¼Œå»ç‰©ç†åŒ–ï¼ˆæ— åå…‰ / å…‰å½± / çº¹ç†ï¼‰ï¼Œä¸è¯»æ–‡å­—ï¼Œä¿ç•™è®¾è®¡å†…å®ç‰©å›¾ï¼ˆå‹¿è¯¯åˆ¤äº§å“å›¾ä¸ºå¹²æ‰°ï¼‰ã€‚
    """
    PROMPT_Gen_BASE = """
    ä¸¥æ ¼éµå¾ªDESCRIBEçš„å¸ƒå±€åˆ†æï¼Œå°†å‚è€ƒå›¾è½¬**æ ‡å‡†ç›´è§’çŸ©å½¢çŸ¢é‡é«˜æ¸…è®¾è®¡ç¨¿**ï¼š 
    * **ç”»å¸ƒ (Canvas)** = **åç‰‡çº¸å¼ è¡¨é¢ (Card Surface)** 
    - æ ¸å¿ƒï¼š1:1 è¿˜åŸåŸå›¾å¸ƒå±€ï¼Œå°†å‚è€ƒå›¾è½¬æ ‡å‡†ç›´è§’çŸ©å½¢ã€çŸ¢é‡é«˜æ¸…ã€æ— å™ªç‚¹ã€å¯å¤ç”¨è®¾è®¡ç¨¿ã€‚æ¶ˆé™¤æ‰€æœ‰ â€œç£¨ç ‚æ„Ÿ / é¢—ç²’æ„Ÿ / çº¸å¼ çº¹ç† / è†œé¢åå…‰â€ã€‚è‰²å— / æ–‡å­— / å›¾æ ‡ä½ç½®ã€å¤§å°ã€è¾¹ç•Œä¸åŸå›¾å®Œå…¨ä¸€è‡´ï¼Œ
    çŸ¢é‡å›¾ï¼Œæ­£è§†å›¾ï¼Œç»å¯¹æ‰å¹³ï¼Œæ— åšåº¦ / é®æŒ¡ / æŠ˜ç—• / é˜´å½± / é€è§† / æ‰­æ›²ï¼Œç»å¯¹çŸ©å½¢ï¼Œæ¸…æ™°æ’ç‰ˆï¼ŒAI è®¾è®¡ç¨¿ï¼Œå»æè´¨åŒ–ï¼Œé«˜ä¿çœŸã€‚
    """
    PROMPT_WithoutVison = """
    åç‰‡ï¼Œå¹²å‡€èƒŒæ™¯ï¼ŒçŸ¢é‡å›¾ï¼Œæ­£è§†å›¾ï¼Œå¹³é¢è®¾è®¡åŸç¨¿ï¼Œç»å¯¹æ‰å¹³ï¼Œæ— åšåº¦ï¼Œæ— é®æŒ¡ï¼Œæ— æŠ˜ç—•ï¼Œæ— é˜´å½±ï¼Œæ— é€è§†ï¼Œæ— æ‰­æ›²ï¼Œç»å¯¹çŸ©å½¢ï¼Œæ¸…æ™°çš„æ–‡å­—æ’ç‰ˆï¼ŒAdobe Illustratorè®¾è®¡ç¨¿ï¼Œå»æè´¨åŒ–ï¼Œé«˜ä¿çœŸã€‚
    """
    PROMPT_V2SIMPLE = """
    å›¾1â€”å›¾ 4ä¸ºå‚è€ƒå›¾ï¼Œå¯¹å›¾äº”è¿›è¡Œå¤„ç†ï¼šåç‰‡ï¼Œå¹³é¢è®¾è®¡åŸç¨¿ï¼ŒçŸ¢é‡å›¾ï¼Œæ­£è§†å›¾ï¼Œå›¾ç‰‡é«˜æ¸…æ— å™ªç‚¹ï¼Œæ‰«æä»ªæ•ˆæœï¼Œç»å¯¹æ‰å¹³ï¼Œæ— åšåº¦ï¼Œæ— é®æŒ¡ï¼Œæ— æŠ˜ç—•ï¼Œæ— é˜´å½±ï¼Œæ— ç¬”è¿¹ï¼Œæ— é€è§†ï¼Œæ— æ‰­æ›²ï¼Œç»å¯¹çŸ©å½¢ï¼Œæ¸…æ™°çš„æ–‡å­—æ’ç‰ˆï¼ŒAdobe Illustratorè®¾è®¡ç¨¿ï¼Œå»æè´¨åŒ–ï¼Œé«˜ä¿çœŸï¼Œç›¸æ¡†ï¼Œçº¢è‰²è¾¹æ¡†å†…ã€‚
    """
    PROMPT_V2STRICT = """
    å›¾ 1â€”å›¾ 4 ä»…ä½œä¸ºã€ç”»è´¨é£æ ¼å‚è€ƒã€‘ï¼ˆä»£è¡¨é«˜æ¸…ã€çŸ¢é‡ã€å¹³æ•´ã€æ— å™ªç‚¹çš„**é£æ ¼**ï¼‰ã€‚
    å›¾ 5 æ˜¯ã€å”¯ä¸€å†…å®¹æºã€‘ï¼ˆä»£è¡¨å¿…é¡»ä¿ç•™çš„Logoã€æ–‡å­—ã€æ’ç‰ˆï¼‰ã€‚

    è¯·ä¸¥æ ¼æ‰§è¡Œä»¥ä¸‹æŒ‡ä»¤å¯¹ å›¾5 è¿›è¡Œé‡ç»˜ï¼š
    1. **å†…å®¹å¿ å®åº¦**ï¼šå¿…é¡»**100% é”å®š**å›¾ 5 çš„åŸå§‹è®¾è®¡å…ƒç´ ã€‚**ç»å¯¹ç¦æ­¢**ä»å›¾ 1â€”å›¾ 4 ä¸­æå–ä»»ä½• Logoã€æ–‡å­—æˆ–ç‰¹å®šçš„èƒŒæ™¯å›¾æ¡ˆåº”ç”¨åˆ°ç»“æœä¸­ã€‚
    2. **ç”»è´¨æå‡**ï¼šåˆ©ç”¨å‚è€ƒå›¾çš„é«˜æ¸…è´¨æ„Ÿï¼Œå°†å›¾ 5 çš„æ¨¡ç³Šåƒç´ è½¬åŒ–ä¸ºæ¸…æ™°çš„çŸ¢é‡çº¿æ¡ã€‚
    
    æ€»ç»“ï¼šåç‰‡ï¼Œå¹³é¢è®¾è®¡åŸç¨¿ï¼ŒçŸ¢é‡å›¾ï¼Œæ­£è§†å›¾ï¼Œå›¾ç‰‡é«˜æ¸…æ— å™ªç‚¹ï¼Œæ‰«æä»ªæ•ˆæœï¼Œç»å¯¹æ‰å¹³ï¼Œæ— åšåº¦ï¼Œæ— é®æŒ¡ï¼Œæ— æŠ˜ç—•ï¼Œæ— é˜´å½±ï¼Œæ— ç¬”è¿¹ï¼Œæ— é€è§†ï¼Œæ— æ‰­æ›²ï¼Œç»å¯¹çŸ©å½¢ï¼Œæ¸…æ™°çš„æ–‡å­—æ’ç‰ˆï¼ŒAdobe Illustratorè®¾è®¡ç¨¿ï¼Œå»æè´¨åŒ–ï¼Œé«˜ä¿çœŸï¼Œç›¸æ¡†ï¼Œçº¢è‰²è¾¹æ¡†å†…ã€‚
    """

    PROMPT_BG_CHECK = """
    è‰²å½©åˆ†æå¸ˆï¼šè¯·åˆ¤æ–­è¿™å¼ å›¾ç‰‡çš„**èƒŒæ™¯è®¾è®¡**æ˜¯å¦ä¸ºã€çº¯è‰²/å•è‰²ã€‘èƒŒæ™¯ã€‚
    
    åˆ¤æ–­æ ‡å‡†ï¼š
    1. å¦‚æœèƒŒæ™¯æ˜¯å•ä¸€é¢œè‰²ï¼ˆå…è®¸æè½»å¾®çš„çº¸å¼ çº¹ç†ï¼Œä½†æ•´ä½“æ˜¯å•è‰²çš„ï¼‰ï¼Œè§†ä¸º Trueã€‚
    2. å¦‚æœèƒŒæ™¯æœ‰æ¸å˜ã€å¤æ‚å›¾æ¡ˆã€ç…§ç‰‡ã€å¤šè‰²å—æ‹¼æ¥ï¼Œè§†ä¸º Falseã€‚
    
    è¯·è¾“å‡ºçº¯ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ï¼š
    {"is_solid": true/false, "hex_color": "#RRGGBB"}
    
    å¦‚æœæ˜¯çº¯è‰²ï¼Œè¯·æå–æœ€ä¸»è¦çš„èƒŒæ™¯ HEX é¢œè‰²ä»£ç ï¼ˆä¾‹å¦‚ #FFFFFF æˆ– #000000ï¼‰ã€‚
    å¦‚æœä¸æ˜¯çº¯è‰²ï¼Œhex_color è¯·è¿”å› null æˆ– ""ã€‚
    """

# ================= 3. ç³»ç»Ÿåˆå§‹åŒ– =================

app = FastAPI(title="Smart Card Restore Ultimate", description="URL Mode + High Quality")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# èµ„æºæ± 
gpu_lock = asyncio.Semaphore(CONFIG.GPU_SEMAPHORE_LIMIT)
api_lock = asyncio.Semaphore(CONFIG.API_SEMAPHORE_LIMIT)
upload_lock = asyncio.Semaphore(CONFIG.UPLOAD_SEMAPHORE_LIMIT)
workflow_lock = asyncio.Semaphore(CONFIG.WORKFLOW_SEMAPHORE_LIMIT)

cpu_executor = ThreadPoolExecutor(max_workers=64)
ark_client = Ark(api_key=CONFIG.VOLC_API_KEY, base_url=CONFIG.VOLC_BASE_URL)
http_client = httpx.AsyncClient(timeout=60.0, limits=httpx.Limits(max_keepalive_connections=500, max_connections=1000))
img_processor = None
# âœ… [æ–°å¢] åˆå§‹åŒ–å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
scheduler = AsyncIOScheduler()
# ================= 4. å‚è€ƒå›¾ä¿æ´»é€»è¾‘ (å…¨æ˜¯æ–°å¢çš„) =================

async def ensure_local_refs():
    """ç¡®ä¿æœ¬åœ°æœ‰å‚è€ƒå›¾æ–‡ä»¶ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸‹è½½åˆå§‹ URL"""
    if not os.path.exists(CONFIG.REF_LOCAL_DIR):
        os.makedirs(CONFIG.REF_LOCAL_DIR)
    
    for i, url in enumerate(CONFIG.REF_IMGS_URLS):
        file_path = os.path.join(CONFIG.REF_LOCAL_DIR, f"ref_{i}.png")
        if not os.path.exists(file_path):
            logger.info(f"ğŸ“¥ [åˆå§‹åŒ–] æœ¬åœ°ç¼ºå°‘å‚è€ƒå›¾ {i+1}ï¼Œæ­£åœ¨ä»åˆå§‹ URL ä¸‹è½½å¤‡ä»½...")
            content = await async_download(url)
            if content:
                with open(file_path, "wb") as f:
                    f.write(content)
                logger.info(f"âœ… [åˆå§‹åŒ–] å‚è€ƒå›¾ {i+1} ä¸‹è½½æˆåŠŸ: {file_path}")
            else:
                logger.error(f"âŒ [åˆå§‹åŒ–] å‚è€ƒå›¾ {i+1} ä¸‹è½½å¤±è´¥! URL: {url}")

async def refresh_reference_images_task():
    """å®šæ—¶ä»»åŠ¡ï¼šè¯»å–æœ¬åœ°å‚è€ƒå›¾ -> ä¸Šä¼  -> æ›´æ–°å†…å­˜ URL"""
    logger.info("â° [å®šæ—¶ä»»åŠ¡] å¼€å§‹æ‰§è¡Œå‚è€ƒå›¾ä¿æ´»ä¸Šä¼ ...")
    
    # 1. ç¡®ä¿æœ¬åœ°æœ‰å›¾
    await ensure_local_refs()
    
    new_urls = []
    success_count = 0
    
    # 2. éå†æœ¬åœ°æ–‡ä»¶å¹¶ä¸Šä¼  (å‡è®¾å›ºå®š4å¼ )
    for i in range(len(CONFIG.REF_IMGS_URLS)): 
        file_path = os.path.join(CONFIG.REF_LOCAL_DIR, f"ref_{i}.png")
        if os.path.exists(file_path):
            try:
                with open(file_path, "rb") as f:
                    content = f.read()
                
                # å¤ç”¨ä¸Šä¼ é€»è¾‘
                new_url = await async_upload(content)
                
                if new_url:
                    new_urls.append(new_url)
                    success_count += 1
                    logger.info(f"âœ… [å®šæ—¶ä»»åŠ¡] å‚è€ƒå›¾ {i+1} ä¸Šä¼ æˆåŠŸ -> {new_url}")
                else:
                    logger.error(f"âŒ [å®šæ—¶ä»»åŠ¡] å‚è€ƒå›¾ {i+1} ä¸Šä¼ å¤±è´¥ï¼Œå°†ä¿ç•™æ—§é“¾æ¥")
                    if i < len(CONFIG.REF_IMGS_URLS):
                        new_urls.append(CONFIG.REF_IMGS_URLS[i])
            except Exception as e:
                logger.error(f"âŒ [å®šæ—¶ä»»åŠ¡] å¤„ç†å‚è€ƒå›¾ {i+1} å¼‚å¸¸: {e}")
                if i < len(CONFIG.REF_IMGS_URLS):
                    new_urls.append(CONFIG.REF_IMGS_URLS[i])
        else:
            logger.error(f"âš ï¸ [å®šæ—¶ä»»åŠ¡] æœ¬åœ°æ–‡ä»¶ä¸¢å¤±: {file_path}")
            if i < len(CONFIG.REF_IMGS_URLS):
                new_urls.append(CONFIG.REF_IMGS_URLS[i])

    # 3. æ›´æ–°å…¨å±€é…ç½®
    if success_count == 4: 
        CONFIG.REF_IMGS_URLS = new_urls
        logger.info(f"ğŸ‰ [å®šæ—¶ä»»åŠ¡] å‚è€ƒå›¾æ± å·²åˆ·æ–°ï¼Œå½“å‰æœ€æ–° URL åˆ—è¡¨: \n{json.dumps(new_urls, indent=2)}")
    else:
        CONFIG.REF_IMGS_URLS = new_urls
        logger.warning(f"âš ï¸ [å®šæ—¶ä»»åŠ¡] å‚è€ƒå›¾åˆ·æ–°å®Œæˆï¼Œä½†æœ‰å¤±è´¥ ({success_count}/4 æˆåŠŸ)")

# ================= ä¿®æ”¹åŸæ¥çš„å¯åŠ¨/å…³é—­äº‹ä»¶ =================

@app.on_event("startup")
async def startup_event():
    global img_processor
    logger.info("â³ æ­£åœ¨åŠ è½½ ResNet æ¨¡å‹(test)...")
    img_processor = processor
    
    # âœ… [ä¼˜åŒ–] å¯åŠ¨å®šæ—¶ä»»åŠ¡ (åŠ  try-except ä¿æŠ¤)
    logger.info("â° æ­£åœ¨å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨...")
    try:
        # 1. ç«‹å³è¿è¡Œä¸€æ¬¡ä¿æ´»
        # æ³¨æ„ï¼šè¿™é‡Œ await ä¼šé˜»å¡å¯åŠ¨ï¼Œç›´åˆ°ä¸‹è½½å®Œæˆã€‚è¿™æ˜¯æœ‰æ„ä¸ºä¹‹ï¼Œç¡®ä¿æœåŠ¡å°±ç»ªæ—¶å‚è€ƒå›¾å¯ç”¨ã€‚
        await refresh_reference_images_task() 
    except Exception as e:
        logger.error(f"âŒ [å¯åŠ¨è­¦å‘Š] åˆå§‹å‚è€ƒå›¾æ›´æ–°å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤æˆ–æ—§ç¼“å­˜: {e}")

    # 2. æ·»åŠ å®šæ—¶ä½œä¸šï¼šæ¯å¤© 00:00 æ‰§è¡Œ
    scheduler.add_job(refresh_reference_images_task, 'cron', hour=0, minute=0)
    scheduler.start()
    
    logger.info(f"ğŸ”¥ ç³»ç»Ÿå¯åŠ¨ | ...")

@app.on_event("shutdown")
async def shutdown_event():
    await http_client.aclose()
    cpu_executor.shutdown()
    # âœ… [æ–°å¢] å…³é—­è°ƒåº¦å™¨
    scheduler.shutdown()

# ================= 4. è¾…åŠ©å‡½æ•° =================


def _bytes_to_b64_str(data: bytes) -> str:
    b64 = base64.b64encode(data).decode('utf-8')
    return f"data:image/jpeg;base64,{b64}"

def _extract_json(content: str) -> dict:
    try:
        if "```json" in content: content = content.split("```json")[1].split("```")[0]
        elif "```" in content: content = content.split("```")[1].split("```")[0]
        return json.loads(content.strip())
    except: return {}

def _pil_to_base64(img: Image.Image) -> str:
    buff = io.BytesIO()
    img.save(buff, format="JPEG", quality=95) # ä¿æŒé«˜æ¸…
    return base64.b64encode(buff.getvalue()).decode('utf-8')

def _pil_to_bytes(img: Image.Image) -> bytes:
    buff = io.BytesIO()
    img.save(buff, format="JPEG", quality=95) # ä¿æŒé«˜æ¸…
    return buff.getvalue()

def _bytes_to_cv2(data: bytes) -> np.ndarray:
    arr = np.frombuffer(data, np.uint8)
    return cv2.imdecode(arr, cv2.IMREAD_COLOR)

def _order_points(pts):
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0], rect[2] = pts[np.argmin(s)], pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1], rect[3] = pts[np.argmin(diff)], pts[np.argmax(diff)]
    return rect

def _try_red_frame_crop_memory(img_bytes: bytes) -> Optional[bytes]:
    try:
        nparr = np.frombuffer(img_bytes, np.uint8)
        img_cv = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if img_cv is None: return None
        hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)
        mask = cv2.bitwise_or(
            cv2.inRange(hsv, np.array([0, 70, 50]), np.array([10, 255, 255])),
            cv2.inRange(hsv, np.array([170, 70, 50]), np.array([180, 255, 255]))
        )
        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5,5), np.uint8))
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours: return None
        c = max(contours, key=cv2.contourArea)
        if cv2.contourArea(c) < 2000: return None
        approx = cv2.approxPolyDP(c, 0.02 * cv2.arcLength(c, True), True)
        if len(approx) == 4:
            pts = _order_points(approx.reshape(4, 2))
            dst = np.array([[0, 0], [2999, 0], [2999, 1823], [0, 1823]], dtype="float32")
            M = cv2.getPerspectiveTransform(pts, dst)
            warped = cv2.warpPerspective(img_cv, M, (3000, 1824))
            return _pil_to_bytes(Image.fromarray(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)))
    except: pass
    return None

# ================= 5. ç½‘ç»œåŠŸèƒ½ =================

async def async_download(url: str) -> Optional[bytes]:
    try:
        resp = await http_client.get(url)
        return resp.content if resp.status_code == 200 else None
    except: return None

async def async_upload(img_bytes: bytes) -> str:
    if not img_bytes: return ""
    async with upload_lock:
        try:
            b64_str = await asyncio.get_event_loop().run_in_executor(
                cpu_executor, lambda: base64.b64encode(img_bytes).decode('utf-8')
            )
            payload = {"base64Str": f"data:image/jpeg;base64,{b64_str}"}
            resp = await http_client.post(CONFIG.UPLOAD_API_URL, json=payload, timeout=180)
            if resp.status_code == 200:
                d = resp.json()
                if d.get("success"): return f"{CONFIG.IMG_URL_PREFIX}{d.get('userData', '')}"
            return ""
        except Exception as e:
            logger.error(f"âš ï¸ Upload Fail: {e}")
            return ""

# ================= 6. æ ¸å¿ƒä¸šåŠ¡ =================

@dataclass
class RestoreStrategy:
    name: str; need_vision: bool; need_ref: bool

STRATEGIES = [
    RestoreStrategy("é™æ€ç”Ÿæˆ", False, False),
    RestoreStrategy("è§†è§‰åˆ†æ", True, False),
    RestoreStrategy("å†…å®¹é”å®š", False, True),
    RestoreStrategy("å‚è€ƒå›¾", False, True)
]

# [ä¿®æ”¹ç‚¹ 3] æ ¸å¿ƒä¸šåŠ¡æµç¨‹é‡å†™
# [ä¿®æ”¹ç‚¹] å¸¦æœ‰è¯¦ç»†è®¡æ—¶åŸ‹ç‚¹çš„æ ¸å¿ƒæµç¨‹
async def process_single_workflow(original_url: str, img_bytes: bytes, filename: str):
    t_start_all = time.time()
    logger.info(f"â–¶ï¸ [å¤„ç†] {filename} ({len(img_bytes)/1024:.0f}KB) | å¼€å§‹è®¡æ—¶")

    # ---------------- 1. GPU çŸ«æ­£ (æœ¬åœ°) ----------------
    t0 = time.time()
    async with gpu_lock:
        def _gpu_task(ib):
            cv_img = _bytes_to_cv2(ib)
            if cv_img is None: return None
            # pil_res = img_processor.process_image_memory(cv_img)
            try:
                # process_image æ”¯æŒç›´æ¥ä¼ å…¥ cv2/numpy æ•°ç»„ï¼Œè¿”å› PIL Image
                pil_res = img_processor.process_image(
                    image_input=cv_img, 
                    model_name="resnet"
                )
                return _pil_to_bytes(pil_res)
            except Exception as e:
                logger.error(f"ResNet Process Error: {e}")
                return None
        
        corr_bytes = await asyncio.get_event_loop().run_in_executor(cpu_executor, _gpu_task, img_bytes)
    t_gpu_end = time.time()
    
    if not corr_bytes:
        logger.error(f"âŒ ResNet Correct Failed: {filename}")
        return {"filename": filename, "status": "failed_correction"}

    # ---------------- 2. å¹¶è¡Œåˆ†æµ ----------------
    
    # [A è·¯] åå°ä¸Šä¼ 
    logger.info("â˜ï¸ [åå°] å¯åŠ¨é™é»˜ä¸Šä¼ çŸ«æ­£å›¾...")
    upload_future = asyncio.create_task(async_upload(corr_bytes))

    # [B è·¯] æé€Ÿè½¬ Base64 (å¢åŠ è€—æ—¶æ‰“å°)
    t_b64_start = time.time()
    corr_base64 = await asyncio.get_event_loop().run_in_executor(
        cpu_executor, _bytes_to_b64_str, corr_bytes
    )
    t_b64_end = time.time()
    
    # [ä¼˜åŒ–] ç”Ÿæˆç¼©ç•¥å›¾ Base64 ç»™ Vision ç”¨ (å¤§å¹…åŠ é€Ÿè§†è§‰åˆ†æ)
    def _make_low_res_b64(ib):
        try:
            with Image.open(io.BytesIO(ib)) as img:
                img.thumbnail((1024, 1024)) 
                buff = io.BytesIO()
                img.save(buff, format="JPEG", quality=85)
                return _bytes_to_b64_str(buff.getvalue())
        except: return corr_base64
    
    corr_base64_small = await asyncio.get_event_loop().run_in_executor(
        cpu_executor, _make_low_res_b64, corr_bytes
    )

    logger.info(f"ğŸ“Š [å‡†å¤‡é˜¶æ®µ] GPUçŸ«æ­£:{t_gpu_end-t0:.2f}s | è½¬Base64:{t_b64_end-t_b64_start:.2f}s | åŸå›¾å¤§å°:{len(corr_base64)/1024/1024:.1f}MB")

    # ---------------- 3. AI è°ƒç”¨å°è£… (å¢åŠ è¯¦ç»†è®¡æ—¶) ----------------

    async def call_vision(p, img_input, is_bg_check=False):
        t_req_start = time.time()
        async with api_lock: 
            t_lock_got = time.time() # æ‹¿åˆ°é”çš„æ—¶é—´
            try:
                content_list = [{"type": "text", "text": p}, {"type": "image_url", "image_url": {"url": img_input}}]
                resp = await asyncio.get_event_loop().run_in_executor(
                    cpu_executor, 
                    lambda: ark_client.chat.completions.create(
                        model=CONFIG.MODEL_VISION,
                        messages=[{"role":"user","content": content_list}]
                    ).choices[0].message.content
                )
                t_req_end = time.time()
                # æ‰“å°è§†è§‰åˆ†æè€—æ—¶
                check_type = "èƒŒæ™¯æ£€æµ‹" if is_bg_check else "å¸ƒå±€åˆ†æ"
                logger.info(f"ğŸ‘ï¸ [{check_type}] æ’é˜Ÿ:{t_lock_got-t_req_start:.2f}s | APIä¼ è¾“+æ¨ç†:{t_req_end-t_lock_got:.2f}s")
                
                if is_bg_check: return _extract_json(resp)
                return resp
            except Exception as e:
                logger.error(f"Vision Error: {e}")
                return {} if is_bg_check else ""

    async def call_gen(p, main_img_input, use_ref, strat_name):
        t_req_start = time.time()
        async with api_lock: 
            t_lock_got = time.time()
            try:
                def _run():
                    imgs = CONFIG.REF_IMGS_URLS[:] if use_ref else []
                    imgs.append(main_img_input) 
                    return ark_client.images.generate(
                        model=CONFIG.MODEL_GEN, prompt=p, image=imgs, 
                        size=CONFIG.FIXED_GEN_SIZE, response_format="url", watermark=False
                    ).data[0].url
                
                url = await asyncio.get_event_loop().run_in_executor(cpu_executor, _run)
                t_req_end = time.time()
                
                # [å…³é”®] æ‰“å° API è€—æ—¶
                logger.info(f"ğŸ“¡ [{strat_name}] æ’é˜Ÿ:{t_lock_got-t_req_start:.2f}s | APIä¼ è¾“+æ¨ç†:{t_req_end-t_lock_got:.2f}s")
                return url
            except Exception as e:
                logger.error(f"Gen Error: {e}")
                return None

    # ---------------- 4. å¯åŠ¨ä»»åŠ¡ ----------------
    
    # è§†è§‰ä»»åŠ¡ç”¨ç¼©ç•¥å›¾ (small)
    task_layout = asyncio.create_task(call_vision(CONFIG.PROMPT_DESCRIBE, corr_base64_small))
    task_bg = asyncio.create_task(call_vision(CONFIG.PROMPT_BG_CHECK, corr_base64_small, is_bg_check=True))

    async def run_strat(strat, layout_desc=""):
        try:
            t_step0 = time.time()
            prompt = ""
            if strat.name == "è§†è§‰åˆ†æ": prompt = f"{CONFIG.PROMPT_Gen_BASE}\nè§†è§‰å‚è€ƒï¼š{layout_desc}"
            elif strat.name == "é™æ€ç”Ÿæˆ": prompt = CONFIG.PROMPT_WithoutVison
            elif strat.name == "å†…å®¹é”å®š": prompt = CONFIG.PROMPT_V2STRICT
            elif strat.name == "å‚è€ƒå›¾": prompt = CONFIG.PROMPT_V2SIMPLE
            else: prompt = CONFIG.PROMPT_Gen_BASE

            logger.info(f"ğŸ¨ [{strat.name}] å‡†å¤‡è¯·æ±‚...")
            
            # 1. ç”Ÿå›¾ (è·å–ä¸´æ—¶ URL)
            gen_temp_url = await call_gen(prompt, corr_base64, strat.need_ref, strat.name)
            if not gen_temp_url: return None
            t_step1 = time.time() # ç”Ÿå›¾ç»“æŸ

            # 2. ä¸‹è½½ (è·å–äºŒè¿›åˆ¶æ•°æ®)
            gen_bytes = await async_download(gen_temp_url)
            if not gen_bytes: return None
            t_step2 = time.time() # ä¸‹è½½ç»“æŸ

            # =========== ã€æ–°å¢ä¿®æ”¹ 1ã€‘å¯åŠ¨ç”Ÿæˆå›¾è½¬å­˜ ===========
            # æ‹¿åˆ° bytes åï¼Œç«‹å³åœ¨åå°å¯åŠ¨ä¸Šä¼ ï¼Œä¸é˜»å¡åç»­çš„è£åˆ‡æµç¨‹
            # è¿™æ ·è£åˆ‡å’Œä¸Šä¼ æ˜¯å¹¶è¡Œçš„ï¼Œå‡ ä¹ä¸å¢åŠ æ€»è€—æ—¶
            task_upload_gen = asyncio.create_task(async_upload(gen_bytes))
            # =================================================

            # 3. è£åˆ‡ (è€—æ—¶æ“ä½œ)
            final_crop_bytes = None
            if strat.name in ["å†…å®¹é”å®š", "å‚è€ƒå›¾"]:
                final_crop_bytes = await asyncio.get_event_loop().run_in_executor(
                    cpu_executor, _try_red_frame_crop_memory, gen_bytes
                )
            
            if final_crop_bytes is None:
                async with gpu_lock:
                    def _gpu_crop_task(ib):
                        cv_img = _bytes_to_cv2(ib)
                        if cv_img is None:
                            return ib
                        try:
                            pil_res = img_processor.process_image(cv_img, model_name="resnet")
                            return _pil_to_bytes(pil_res)
                        except:
                            return ib

                    final_crop_bytes = await asyncio.get_event_loop().run_in_executor(
                    cpu_executor, _gpu_crop_task, gen_bytes
                        )

            t_step3 = time.time() # è£åˆ‡ç»“æŸ
            
            # 4. ä¸Šä¼ è£åˆ‡å›¾
            u_crop = await async_upload(final_crop_bytes)
            
            # =========== ã€æ–°å¢ä¿®æ”¹ 2ã€‘ç­‰å¾…ç”Ÿæˆå›¾ä¸Šä¼ å®Œæˆ ===========
            # æ­¤æ—¶è£åˆ‡å›¾å·²ç»ä¸Šä¼ å®Œæ¯•ï¼Œç”Ÿæˆå›¾çš„ä¸Šä¼ é€šå¸¸ä¹Ÿæ—©å°±å®Œæˆäº†
            u_gen_permanent = await task_upload_gen
            
            # å¦‚æœä¸Šä¼ å¤±è´¥ï¼ˆè¿”å›ç©ºï¼‰ï¼Œä¸ºäº†ä¿é™©èµ·è§ï¼Œå¯ä»¥å›é€€ä½¿ç”¨ä¸´æ—¶ URLï¼Œæˆ–è€…ç›´æ¥ç•™ç©º
            # è¿™é‡Œæˆ‘é€»è¾‘è®¾ä¸ºï¼šå¦‚æœä¸Šä¼ æˆåŠŸç”¨æ–°é“¾æ¥ï¼Œå¤±è´¥äº†ç”¨è±†åŒ…ä¸´æ—¶é“¾æ¥é¡¶ä¸€ä¸‹
            final_gen_url = u_gen_permanent if u_gen_permanent else gen_temp_url
            # ===================================================

            t_step4 = time.time() # ä¸Šä¼ ç»“æŸ
            
            # 5. æ‰“å°è¯¦æƒ…
            total_t = t_step4 - t_step0
            api_t = t_step1 - t_step0
            dl_t = t_step2 - t_step1
            crop_t = t_step3 - t_step2
            up_t = t_step4 - t_step3
            
            logger.info(f"âœ… [{strat.name}] æ€»:{total_t:.1f}s | API:{api_t:.1f}s | ä¸‹è½½:{dl_t:.1f}s | è£åˆ‡:{crop_t:.1f}s | ä¸Šä¼ :{up_t:.1f}s")
            
            return {
                "strategy_name": strat.name,
                "crop_image_url": u_crop,      # è£åˆ‡åçš„æ°¸ä¹…é“¾æ¥
                "gen_image_url": final_gen_url # ã€å·²ä¿®æ”¹ã€‘ç”Ÿæˆå›¾çš„æ°¸ä¹…é“¾æ¥
            }
        except Exception as e:
            logger.error(f"Strat Error {strat.name}: {e}")
            return None

    # ================= ğŸš€ ä¿®æ­£åçš„è°ƒåº¦é€»è¾‘ =================
    
    running_tasks = []

    # 1. ç¬¬ä¸€æ¢¯é˜Ÿï¼šã€ä¸éœ€è¦ã€‘è§†è§‰åˆ†æçš„ä»»åŠ¡ï¼Œç«‹åˆ» create_task å‘è½¦ï¼
    for s in STRATEGIES:
        if not s.need_vision: 
            running_tasks.append(asyncio.create_task(run_strat(s)))
    
    # 2. ä¸­é—´å¡ç‚¹ï¼šç­‰å¾… Layout ç»“æœ
    layout_res = ""
    try: 
        layout_res = await task_layout
    except: pass
        
    # 3. ç¬¬äºŒæ¢¯é˜Ÿï¼šã€éœ€è¦ã€‘è§†è§‰åˆ†æçš„ä»»åŠ¡ï¼Œæ‹¿åˆ°ç»“æœåå‘è½¦
    for s in STRATEGIES:
        if s.need_vision: 
            running_tasks.append(asyncio.create_task(run_strat(s, layout_res)))

    gen_results = await asyncio.gather(*running_tasks)
    
    # ---------------- 5. æ”¶å°¾åŒæ­¥ ----------------
    logger.info("â³ æ­£åœ¨å›æ”¶åå°ä¸Šä¼ ä»»åŠ¡...")
    corr_url_final = await upload_future 
    
    try: bg_info = await task_bg
    except: bg_info = {"is_solid": False, "hex_color": ""}

    logger.info(f"ğŸ‰ [ç»“æŸ] {filename} å¤„ç†å®Œæ¯• | å…¨ç¨‹è€—æ—¶: {time.time()-t_start_all:.1f}s")
    
    return {
        "filename": filename,
        "status": "success",
        "original_image_url": original_url,
        "corrected_image_url": corr_url_final,
        "background_info": bg_info, 
        "generations": [r for r in gen_results if r]
    }

# ================= 7. API è·¯ç”± =================

class UrlBatchRequest(BaseModel):
    urls: List[str]

@app.post("/restore_batch_url")
async def restore_batch_url(req: UrlBatchRequest):
    logger.info(f"ğŸ“¨ æ”¶åˆ° URL æ‰¹é‡è¯·æ±‚: {len(req.urls)} ä¸ª")
    if not req.urls: raise HTTPException(400, "No URLs")
    
    async def _worker(url, idx):
        # åŒæ ·åŠ é”ï¼Œé™åˆ¶åŒæ—¶ä¸‹è½½çš„å›¾ç‰‡æ•°é‡
        async with workflow_lock:
            ib = await async_download(url)
            if not ib: return {"filename": url, "status": "failed_download"}
            return await process_single_workflow(url, ib, f"url_{idx}")
            
    tasks = [_worker(u, i) for i, u in enumerate(req.urls)]
    results = await asyncio.gather(*tasks)
    return {"total": len(req.urls), "success": len([r for r in results if r['status']=='success']), "results": results}

@app.post("/restore_batch_file")
async def restore_batch_file(files: List[UploadFile] = File(...)):
    logger.info(f"ğŸ“‚ æ”¶åˆ°æ–‡ä»¶æ‰¹é‡è¯·æ±‚: {len(files)} ä¸ª")
    
    async def _worker(file):
        # [å…³é”®] åœ¨è¯»å–æ–‡ä»¶å†…å®¹ä¹‹å‰ï¼Œå…ˆç”³è¯·â€œå‡†å…¥è¯â€
        # åªæœ‰æ‹¿åˆ°é”çš„ä»»åŠ¡ï¼Œæ‰å…è®¸æŠŠæ–‡ä»¶è¯»å…¥å†…å­˜ï¼Œé˜²æ­¢ OOM
        async with workflow_lock:
            # 1. è¯»å–æ–‡ä»¶å†…å®¹ (åªæœ‰ 15 ä¸ªä»»åŠ¡èƒ½åŒæ—¶è¿è¡Œåˆ°è¿™é‡Œ)
            content = await file.read()
            
            # 2. å¯åŠ¨åå°ä¸Šä¼ 
            logger.info(f"â¬†ï¸ [åå°] åŸå›¾å¼€å§‹é™é»˜ä¸Šä¼ : {file.filename}")
            task_upload_src = asyncio.create_task(async_upload(content))
            
            # 3. å¯åŠ¨ AI å¤„ç†
            process_task = asyncio.create_task(process_single_workflow("", content, file.filename))
            
            # 4. ç­‰å¾…å®Œæˆ
            result = await process_task
            real_src_url = await task_upload_src
            
            # 5. å¡«è¡¥ URL
            if result["status"] == "success":
                result["original_image_url"] = real_src_url
            
            return result

    # è¿™é‡Œè™½ç„¶åˆ›å»ºäº†æ‰€æœ‰ taskï¼Œä½†å®ƒä»¬ä¼šåœ¨ `async with workflow_lock` å¤„æ’é˜Ÿ
    # ä¸ä¼šæ¶ˆè€—å†…å­˜å» read() æ–‡ä»¶
    tasks = [_worker(f) for f in files]
    results = await asyncio.gather(*tasks)
    return {"total": len(files), "success": len([r for r in results if r['status']=='success']), "results": results}

if __name__ == "__main__":
    import uvicorn
    # ç»Ÿä¸€ä½¿ç”¨ 6003 ç«¯å£
    uvicorn.run(app, host="0.0.0.0", port=6003, workers=1)
# -*- coding: utf-8 -*-
"""
@File       : image_correct.py
@Author     : Duangang Qu
@Email      : quduangang@outlook.com
@Created    : 2025/9/1 11:57
@Modified   : 2025/12/24 (Optimized for High Resolution)
@Software   : PyCharm
@Description: å›¾åƒçŸ«æ­£ä¸å¢å¼ºå¤„ç†ï¼ˆä¼˜åŒ–æ¸…æ™°åº¦ç‰ˆï¼‰
"""

import base64
import io
import json
import numpy as np
import cv2
import pytesseract
import requests
from PIL import Image, ImageOps
from typing import Union, Optional
import tempfile
import os

# å¯¼å…¥ModelScopeç›¸å…³æ¨¡å—
from modelscope.pipelines import pipeline
from modelscope.utils.constant import Tasks

# å¯¼å…¥è…¾è®¯äº‘SDKç›¸å…³æ¨¡å—
from tencentcloud.common import credential
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.common.exception.tencent_cloud_sdk_exception import TencentCloudSDKException
from tencentcloud.ocr.v20181119 import ocr_client, models

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from textDirectionDetection import text_orientation
from config import TENCENT_CONFIG, TEXTIN_CONFIG, RESNET_CONFIG, IMAGE_CONFIG, SUPPORTED_MODELS


class ImageProcessor:
    """å›¾åƒå¤„ç†ç±»ï¼Œæ”¯æŒå¤šç§OCRå’Œå›¾åƒå¢å¼ºæœåŠ¡"""

    def __init__(self):
        """åˆå§‹åŒ–å›¾åƒå¤„ç†å™¨"""
        self.tencent_config = TENCENT_CONFIG
        self.textin_config = TEXTIN_CONFIG
        self.resnet_config = RESNET_CONFIG
        self.image_config = IMAGE_CONFIG

        # åˆå§‹åŒ–ResNetæ¨¡å‹
        self.card_detection_correction = pipeline(
            Tasks.card_detection_correction,
            model=self.resnet_config["MODEL_ID"]
        )

    def process_image(self, image_input: Union[str, Image.Image, np.ndarray],
                      model_name: str, output_path: Optional[str] = None) -> Union[Image.Image, str]:
        """
        å¤„ç†å›¾åƒçš„ä¸»æ¥å£
        """
        if model_name.lower() not in SUPPORTED_MODELS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. æ”¯æŒçš„æ¨¡å‹: {SUPPORTED_MODELS}")

        # æ ‡å‡†åŒ–è¾“å…¥å›¾åƒ
        pil_image, temp_path = self._standardize_input(image_input)

        try:
            # ä¿®å¤EXIFæ–¹å‘
            pil_image = self._fix_image_orientation(pil_image)

            # è½¬æ¢ä¸ºOpenCVæ ¼å¼è¿›è¡Œæ–¹å‘æ ¡æ­£
            cv2_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)
            corrected_image = self._correct_text_orientation(cv2_image)

            # [ä¼˜åŒ–1] ä¿å­˜æ ¡æ­£åçš„å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
            # ä¿®æ”¹ï¼šä½¿ç”¨ .png åç¼€ï¼Œé¿å…ä¸­é—´ç¯èŠ‚çš„ JPG æœ‰æŸå‹ç¼©
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                corrected_temp_path = temp_file.name
                cv2.imwrite(corrected_temp_path, corrected_image)

            # æ ¹æ®æ¨¡å‹ç±»å‹å¤„ç†å›¾åƒ
            if model_name.lower() == 'resnet':
                result_image = self._process_with_resnet(corrected_temp_path)
            elif model_name.lower() == 'textin':
                result_image = self._process_with_textin(corrected_temp_path)
            elif model_name.lower() == 'tencent':
                result_image = self._process_with_tencent(corrected_temp_path)

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path and os.path.exists(temp_path):
                os.unlink(temp_path)
            if os.path.exists(corrected_temp_path):
                os.unlink(corrected_temp_path)

            # [ä¼˜åŒ–2] æœ€ç»ˆå°ºå¯¸è°ƒæ•´é€»è¾‘
            # ç›®æ ‡å°ºå¯¸
            target_size = (3000, 1824)
            
            # ä½¿ç”¨ LANCZOS é«˜è´¨é‡æ’å€¼ç®—æ³•è¿›è¡Œç¼©æ”¾ï¼Œé¿å…ç›´æ¥ resize å¯¼è‡´çš„æ¨¡ç³Š
            if result_image.size != target_size:
                print(f"æ­£åœ¨è°ƒæ•´å°ºå¯¸ (LANCZOS): {result_image.size} -> {target_size}")
                result_image = result_image.resize(target_size, Image.Resampling.LANCZOS)

            # å¤„ç†è¾“å‡º
            if output_path:
                result_image.save(output_path, 'JPEG', quality=self.image_config.get("JPEG_QUALITY", 95))
                return output_path
            else:
                return result_image

        except Exception as e:
            # å¼‚å¸¸å‘ç”Ÿæ—¶ä¹Ÿè¦æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_path and os.path.exists(temp_path):
                os.unlink(temp_path)
            if 'corrected_temp_path' in locals() and os.path.exists(corrected_temp_path):
                os.unlink(corrected_temp_path)
            raise Exception(f"å›¾åƒå¤„ç†å¤±è´¥: {str(e)}")

    def _standardize_input(self, image_input: Union[str, Image.Image, np.ndarray]) -> tuple:
        """æ ‡å‡†åŒ–è¾“å…¥å›¾åƒæ ¼å¼"""
        temp_path = None

        if isinstance(image_input, str):
            if not os.path.exists(image_input):
                raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_input}")
            pil_image = Image.open(image_input).convert('RGB')
        elif isinstance(image_input, Image.Image):
            pil_image = image_input.convert('RGB')
        elif isinstance(image_input, np.ndarray):
            if len(image_input.shape) == 3:
                image_input = cv2.cvtColor(image_input, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image_input).convert('RGB')
        else:
            raise TypeError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(image_input)}")

        return pil_image, temp_path

    def _fix_image_orientation(self, img: Image.Image) -> Image.Image:
        """ä¿®å¤å›¾åƒEXIFå…ƒæ•°æ®ä¸­çš„æ–¹å‘"""
        try:
            return ImageOps.exif_transpose(img)
        except Exception as e:
            print(f"EXIFæ–¹å‘ä¿®å¤å¤±è´¥: {e}")
            return img

    def _correct_text_orientation(self, image_cv2: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨Tesseract OSDæ£€æµ‹æ–‡æœ¬æ–¹å‘å¹¶è‡ªåŠ¨æ—‹è½¬å›¾åƒ"""
        try:
            print("æ­£åœ¨æ£€æµ‹æ–‡æœ¬æ–¹å‘...")
            gray_image = cv2.cvtColor(image_cv2, cv2.COLOR_BGR2GRAY)
            _, processed_image = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

            osd = pytesseract.image_to_osd(processed_image, output_type=pytesseract.Output.DICT)

            rotation = osd.get('rotate', 0)
            print(f"æ£€æµ‹åˆ°çš„æ—‹è½¬è§’åº¦: {rotation} åº¦")

            if rotation != 0:
                print(f"éœ€è¦æ—‹è½¬ï¼Œæ­£åœ¨æ ¡æ­£...")
                if rotation == 90:
                    corrected_image = cv2.rotate(image_cv2, cv2.ROTATE_90_COUNTERCLOCKWISE)
                elif rotation == 180:
                    corrected_image = cv2.rotate(image_cv2, cv2.ROTATE_180)
                elif rotation == 270:
                    corrected_image = cv2.rotate(image_cv2, cv2.ROTATE_90_CLOCKWISE)
                else:
                    corrected_image = image_cv2
                print("æ–¹å‘æ ¡æ­£å®Œæˆã€‚")
                return corrected_image
            else:
                print("æ–‡æœ¬æ–¹å‘æ­£ç¡®ï¼Œæ— éœ€æ—‹è½¬ã€‚")
                return image_cv2
        except Exception as e:
            print(f"æ–‡æœ¬æ–¹å‘æ£€æµ‹å¤±è´¥: {e}")
            return image_cv2

    def _process_with_resnet(self, image_path: str) -> Image.Image:
        """ä½¿ç”¨ResNetæ¨¡å‹å¤„ç†å›¾åƒ"""
        try:
            print("æ­£åœ¨ä½¿ç”¨ResNetå¤„ç†å›¾åƒ...")
            result = self.card_detection_correction(image_path)

            if "output_imgs" in result and len(result["output_imgs"]) > 0:
                img = result["output_imgs"][0]
                
                # [ä¼˜åŒ–3] å…³é”®ä¿®æ”¹ï¼šå–æ¶ˆä¸­é—´æ­¥éª¤çš„å¼ºåˆ¶é™é‡‡æ ·
                # âŒ åŸä»£ç ï¼šresized_img = cv2.resize(img, self.image_config["OUTPUT_SIZE"])
                # âœ… æ–°ä»£ç ï¼šç›´æ¥ä¿ç•™æ¨¡å‹è¾“å‡ºçš„é«˜æ¸…åŸå›¾
                resized_img = img 

                # æ–‡æœ¬æ–¹å‘æ£€æµ‹å’Œæ ¡æ­£
                label, score = text_orientation(resized_img)
                angle_to_correct = 360 - int(label[0])

                if angle_to_correct == 90:
                    rotated_img = cv2.rotate(resized_img, cv2.ROTATE_90_COUNTERCLOCKWISE)
                elif angle_to_correct == 180:
                    rotated_img = cv2.rotate(resized_img, cv2.ROTATE_180)
                elif angle_to_correct == 270:
                    rotated_img = cv2.rotate(resized_img, cv2.ROTATE_90_CLOCKWISE)
                else:
                    rotated_img = resized_img

                # è½¬æ¢ä¸ºPIL Image
                rotated_img_rgb = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB)
                return Image.fromarray(rotated_img_rgb)
            else:
                raise Exception("ResNetå¤„ç†å¤±è´¥ï¼šæœªè¿”å›æœ‰æ•ˆç»“æœ")
        except Exception as e:
            raise Exception(f"ResNetå¤„ç†å¤±è´¥: {str(e)}")

    def _process_with_textin(self, image_path: str) -> Image.Image:
        """ä½¿ç”¨åˆåˆä¿¡æ¯å¤„ç†å›¾åƒ"""
        try:
            print("æ­£åœ¨ä½¿ç”¨åˆåˆä¿¡æ¯å¤„ç†å›¾åƒ...")

            headers = {
                'x-ti-app-id': self.textin_config["APP_ID"],
                'x-ti-secret-code': self.textin_config["SECRET_CODE"],
                'Content-Type': 'application/octet-stream'
            }

            with open(image_path, 'rb') as f:
                body = f.read()

            response = requests.post(
                self.textin_config["URL"],
                params=self.textin_config["API_PARAMS"],
                data=body,
                headers=headers
            )
            response.raise_for_status()

            result = json.loads(response.text)

            if result and 'result' in result and result['result']['image_list']:
                image_data = base64.b64decode(result['result']['image_list'][0]["image"])
                img = Image.open(io.BytesIO(image_data))

                # æ–‡æœ¬æ–¹å‘æ£€æµ‹å’Œæ ¡æ­£
                label, score = text_orientation(img)
                resized_img_angle = 360 - int(label[0])

                img = img.rotate(resized_img_angle)
                
                # è¿™é‡Œä¹Ÿå¯ä»¥è€ƒè™‘æ˜¯å¦éœ€è¦ç§»é™¤ä¸­é—´ç¼©æ”¾ï¼Œå–å†³äº textin è¿”å›çš„å›¾æ˜¯å¦å·²ç»å¤Ÿå¤§äº†
                # å¦‚æœ textin è¿”å›çš„æœ¬èº«å°±æ˜¯é«˜æ¸…çš„ï¼Œè¿™é‡Œä¿ç•™ LANCZOS æ˜¯å¯¹çš„ï¼Œä½†å¦‚æœä¸­é—´æƒ³ä¿æŒæœ€å¤§åŒ–ï¼Œå¯ä»¥å…ˆå»æ‰
                img_resized = img.resize(self.image_config["OUTPUT_SIZE"], Image.Resampling.LANCZOS)

                return img_resized.convert('RGB')
            else:
                raise Exception(f"åˆåˆä¿¡æ¯å¤„ç†å¤±è´¥ï¼šAPIæœªè¿”å›æœ‰æ•ˆå›¾åƒæ•°æ®")

        except Exception as e:
            raise Exception(f"åˆåˆä¿¡æ¯å¤„ç†å¤±è´¥: {str(e)}")

    def _process_with_tencent(self, image_path: str) -> Image.Image:
        """ä½¿ç”¨è…¾è®¯äº‘å¤„ç†å›¾åƒ"""
        try:
            print("æ­£åœ¨ä½¿ç”¨è…¾è®¯äº‘å¤„ç†å›¾åƒ...")

            with open(image_path, "rb") as f:
                img_base64 = base64.b64encode(f.read()).decode('utf-8')

            enhanced_base64 = self._enhance_image_tencent(img_base64)

            if enhanced_base64:
                enhanced_data = base64.b64decode(enhanced_base64)
                enhanced_img = Image.open(io.BytesIO(enhanced_data))

                # æ–‡æœ¬æ–¹å‘æ£€æµ‹å’Œæ ¡æ­£
                label, score = text_orientation(enhanced_img)
                resized_img_angle = 360 - int(label[0])

                enhanced_img = enhanced_img.rotate(resized_img_angle)
                enhanced_img_resized = enhanced_img.resize(
                    self.image_config["OUTPUT_SIZE"],
                    Image.Resampling.LANCZOS
                )

                return enhanced_img_resized.convert('RGB')
            else:
                raise Exception("è…¾è®¯äº‘å¤„ç†å¤±è´¥ï¼šæœªè·å–åˆ°å¢å¼ºå›¾åƒ")

        except Exception as e:
            raise Exception(f"è…¾è®¯äº‘å¤„ç†å¤±è´¥: {str(e)}")

    def _enhance_image_tencent(self, image_base64: str) -> Optional[str]:
        """è°ƒç”¨è…¾è®¯äº‘æ–‡æœ¬å›¾åƒå¢å¼ºæ¥å£"""
        try:
            cred = credential.Credential(
                self.tencent_config["SECRET_ID"],
                self.tencent_config["SECRET_KEY"]
            )
            http_profile = HttpProfile()
            http_profile.endpoint = self.tencent_config["ENDPOINT"]
            client_profile = ClientProfile()
            client_profile.httpProfile = http_profile
            client = ocr_client.OcrClient(cred, self.tencent_config["REGION"], client_profile)

            req = models.ImageEnhancementRequest()
            params = {
                "ImageBase64": image_base64,
                "ReturnImage": "preprocess",
                "TaskType": 1
            }
            req.from_json_string(json.dumps(params))

            resp = client.ImageEnhancement(req)
            return resp.Image
        except TencentCloudSDKException as err:
            print(f"è…¾è®¯äº‘APIè°ƒç”¨å¤±è´¥: {err}")
            return None


processor = ImageProcessor()

def get_Corrected_image(image_path):
    return processor.process_image(image_path, model_name="resnet")

if __name__ == '__main__':
    """
    ImageProcessor ä½¿ç”¨ç¤ºä¾‹
    """
    # print("ç¤ºä¾‹: å¤„ç†æœ¬åœ°å›¾åƒæ–‡ä»¶ (ResNeté«˜æ¸…ä¼˜åŒ–ç‰ˆ)")
    # try:
    #     # ä¿®æ”¹ä¸ºä½ çš„å®é™…è·¯å¾„
    #     input_file = "/root/autodl-tmp/image.png"
    #     output_file = "/root/autodl-tmp/image_crop.png"
        
    #     if os.path.exists(input_file):
    #         result_path = processor.process_image(
    #             image_input=input_file,
    #             model_name="resnet",
    #             output_path=output_file
    #         )
    #         print(f"âœ… å¤„ç†å®Œæˆ! ç»“æœå·²ä¿å­˜è‡³: {result_path}")
    #         # å¯ä»¥æ‰“å°ä¸€ä¸‹æœ€ç»ˆå°ºå¯¸ç¡®è®¤
    #         with Image.open(result_path) as img:
    #             print(f"ğŸ“ æœ€ç»ˆå°ºå¯¸: {img.size}")
    #     else:
    #         print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            
    # except Exception as e:
    #     print(f"âŒ å¤„ç†å¤±è´¥: {e}")


    print("\nç¤ºä¾‹: æ‰¹é‡å¤„ç†å›¾åƒ")
    import os
    
    def batch_process_images(input_dir, output_dir, model_name):
        """æ‰¹é‡å¤„ç†å›¾åƒ"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
    
        supported_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}
        image_files = [f for f in os.listdir(input_dir)
                       if os.path.splitext(f.lower())[1] in supported_extensions]
    
        for i, filename in enumerate(image_files, 1):
            print(f"å¤„ç†ç¬¬ {i}/{len(image_files)} ä¸ªæ–‡ä»¶: {filename}")
    
            try:
                input_path = os.path.join(input_dir, filename)
                output_filename = f"{model_name}_{os.path.splitext(filename)[0]}.jpg"
                output_path = os.path.join(output_dir, output_filename)
    
                # å¤„ç†å›¾åƒ
                processor.process_image(
                    image_input=input_path,
                    model_name=model_name,
                    output_path=output_path
                )
    
                print(f"  å¤„ç†å®Œæˆ: {output_path}")
    
            except Exception as e:
                print(f"  å¤„ç†å¤±è´¥: {e}")
    
    # æ‰¹é‡å¤„ç†ç¤ºä¾‹ï¼ˆéœ€è¦ä¿®æ”¹è·¯å¾„ï¼‰
    batch_process_images(
        input_dir="/root/autodl-tmp/img",
        output_dir="/root/autodl-tmp/img_only",
        model_name="resnet"
    )